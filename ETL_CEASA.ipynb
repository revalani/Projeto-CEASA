{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Acessar site e coletar os PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% ## instalar dependencias\n",
    "%env\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports, variaveis globais \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re #regex\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "URL_CEASA = 'https://www.ceasa.rj.gov.br'\n",
    "URL_CEASA_cotacao = URL_CEASA+'Cota%C3%A7%C3%A3o'\n",
    "\n",
    "PASTA_PDFs = \"./pdfs/\"\n",
    "PASTA_DADOS = \"./dados/\"\n",
    "\n",
    "ceasa_lista_pdf = PASTA_DADOS+\"ceasa_lista_pdf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### auxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barra de progresso\n",
    "# font:https://stackoverflow.com/questions/6169217/replace-console-output-in-python\n",
    "\n",
    "def print_r(str:str):\n",
    "    print(str, end='\\r')\n",
    "\n",
    "\n",
    "def print_percent_done(index, total, progress_state=None, bar_len=25, title='Please wait'):\n",
    "    '''\n",
    "    index is expected to be 0 based index. \n",
    "    0 <= index < total\n",
    "    '''\n",
    "    percent_done = (index+1)/total*100\n",
    "    percent_done = round(percent_done, 1)\n",
    "\n",
    "    done = round(percent_done/(100/bar_len))\n",
    "    togo = bar_len-done\n",
    "\n",
    "    done_str = '█'*int(done)\n",
    "    togo_str = '░'*int(togo)\n",
    "\n",
    "    progress_state = f\"\\t Stage: {progress_state}\" if progress_state else ''\n",
    "\n",
    "    print(f'\\t⏳{title}: [{done_str}{togo_str}] {percent_done}% done {progress_state}', end='\\r')\n",
    "\n",
    "    if round(percent_done) == 100:\n",
    "        print('\\t✅')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "def foi_extraida(url):\n",
    "\treturn True if url in((df_extração['URL'].eq(url))) else False\n",
    "\n",
    "def pegar_links(url):\n",
    "\t\"\"\"\n",
    "\t\tFunção recursiva que entra no site em busca links das tags 'a' na div com id=\"main\" e entra no novo site em busta de links. ele para quando encrontra uma url com '.pdf'.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\turl (str):endereço da pagina html a ser percorrida\n",
    "\t\t\t\t(opcional)\n",
    "\n",
    "\t\tReturn:\n",
    "\t\t\tNone\n",
    "\t\"\"\"\n",
    "\t\n",
    "\treqs = requests.get(url)\n",
    "\tsoup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "\tfor link in soup.select('#main a'):\n",
    "\t\t\n",
    "\t\ta = str(link.get('href'))\n",
    "\t\tprint_r(f'Qtds pdfs encontrados {len(urls)}, link atual: {a}')\n",
    "\t\tif \".pdf\" in a:\n",
    "\t\t\ta = 'https://www.ceasa.rj.gov.br'+ a\n",
    "\t\t\tif not foi_extraida(a):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\turls.append(a)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t\tpegar_links(a)\n",
    "\n",
    "def extrair_dados_url(url):\n",
    "\t\"\"\"\n",
    "\t\t\tPega a url do PDF e extrai data, nome do documento e link do pdf\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\tlink: str\n",
    "\t\t\t\turl do documento pdf\n",
    "\n",
    "\t\tReturn:\n",
    "\t\t\turl: str\n",
    "\t\t\tnome_arquivo: str\n",
    "\t\t\tdata: str\n",
    "\t\"\"\"\n",
    "\t# pega nome do arquivo na URL\n",
    "\tnome_arquivo = url.split(\"/\")[-1]\n",
    "\tnome_arquivo = requests.utils.unquote(nome_arquivo) # type: ignore\n",
    "\n",
    "\t# padrao de dd mm yyyy para data\n",
    "\tmatches = re.findall(r'(\\d{2})\\s(\\d{2})\\s(\\d{4})', nome_arquivo)\n",
    "\tdata = dt.strptime(\"/\".join(matches[0]), \"%d/%m/%Y\")\n",
    "\n",
    "\treturn url,\"CEASA-RJ_\" + nome_arquivo.replace(\" \", \"_\") ,data.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "def pegar_pdf(url,nome_arquivo):\n",
    "\t# conferir se ja está na base local\n",
    "\tresponse = requests.get(url)\n",
    "\n",
    "\tif response.status_code == 200:\n",
    "\t\twith open(PASTA_PDFs+nome_arquivo, \"wb\") as f:\n",
    "\t\t\tf.write(response.content)\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "def add_csv(url, nome_arquivo,data):\n",
    "\tdata_to_file = {\n",
    "\t\t'URL': [url],\n",
    "\t\t'nome_arquivo': [nome_arquivo],\n",
    "\t\t'data': [data]\n",
    "\t} \n",
    "\tdf = pd.DataFrame(data_to_file)\n",
    "\tdf.to_csv(ceasa_lista_pdf, mode='a', index=False, header=False, sep=\";\")\n",
    "\n",
    "def atualizar_base_pdf():\n",
    "\tpegar_links(URL_CEASA_cotacao)\n",
    "\t\n",
    "\tfor x in urls[:]:\n",
    "\t\tprint_percent_done(\n",
    "\t\tlen(df_extração) - len(urls), \n",
    "\t\tlen(df_extração), \n",
    "\t\tstr(f'pdf extraidos {len(urls)} de {len(df_extração)} \\n\\t link atual {x}'))\n",
    "\n",
    "\t\t# if foi_extraida:\n",
    "\t\t# \tcontinue\n",
    "\t\t\n",
    "\t\turl, nome_arquivo, data = extrair_dados_url(x)\n",
    "\t\tpegar_pdf(url,nome_arquivo)\n",
    "\t\tadd_csv(url,nome_arquivo,data)\n",
    "\n",
    "\n",
    "# init\n",
    "\n",
    "try:\n",
    "    urls # type: ignore\n",
    "except:\n",
    "\turls = [] \n",
    "\n",
    "\n",
    "try:\n",
    "\tdf_extração = pd.read_csv(ceasa_lista_pdf,sep=\";\")\n",
    "except:\n",
    "\tdf_extração = pd.read_csv(ceasa_lista_pdf,sep=\";\", names = [\"URL\", \"nome_arquivo\",\"data\"])\n",
    "\tdf_extração.to_csv(ceasa_lista_pdf, sep=';', index=False)\n",
    "\n",
    "atualizar_base_pdf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando os PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compressão paralelizada (muito custoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "import PyPDF2\n",
    "import concurrent.futures\n",
    "\n",
    "def compress_pdf(input_path, output_path):\n",
    "    with open(input_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page.compress_content_streams()\n",
    "            pdf_writer.add_page(page)\n",
    "\n",
    "        with open(output_path, 'wb') as output_file:\n",
    "            pdf_writer.write(output_file)\n",
    "\n",
    "def process_pdf(file_name):\n",
    "    print(f'arquivo atual: {file_name}')\n",
    "    compress_pdf(PASTA_PDFs + file_name, PASTA_PDFs + file_name)\n",
    "\n",
    "# Sua lista de arquivos\n",
    "files_to_process = df_extração[\"nome_arquivo\"].tolist()\n",
    "\n",
    "# Número máximo de threads (ajuste conforme necessário)\n",
    "max_threads = 4\n",
    "\n",
    "# Usando ThreadPoolExecutor para paralelizar\n",
    "with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "    futures = [executor.submit(process_pdf, file_name) for file_name in files_to_process]\n",
    "\n",
    "    # Esperar que todas as threads concluam\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        count += 1 # type: ignore\n",
    "        print_percent_done(count, len(files_to_process), future.result()) # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo Tabelas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartir de 29-03-2023 ouver mudança na formatação da tabela.\n",
    "trataremos as duas versões de PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "arq = ceasa_lista_pdf\n",
    "\n",
    "df_extração = pd.read_csv(arq)\n",
    "\n",
    "pdf_v1 = PASTA_PDFs + \"CEASA-RJ_Boletim_diário_de_preços__03_01_2022_0.pdf\" \n",
    "pdf_v2 = PASTA_PDFs + \"CEASA-RJ_Boletim_diário_de_preços__24_04_2023.pdf\" \n",
    "\n",
    "\n",
    "\n",
    "def extrair_tabelas(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Itera sobre todas as páginas do PDF\n",
    "        for page_number in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_number]\n",
    "\n",
    "            # Extrai todas as tabelas na página\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            # Itera sobre todas as tabelas na página\n",
    "            for table_number, table in enumerate(tables):\n",
    "                print(f\"Tabela {table_number + 1} na página {page_number + 1}:\")\n",
    "                \n",
    "                # Itera sobre todas as linhas da tabela\n",
    "                for row_number, row in enumerate(table):\n",
    "                    print(f\"  Linha {row_number + 1}: {row}\")\n",
    "\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador entre tabelas\n",
    "\n",
    "\n",
    "def extrair_tabela_pdf(pdf_path, pagina=0):\n",
    "    # Abre o PDF com pdfplumber\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Seleciona a página desejada\n",
    "        page = pdf.pages[pagina]\n",
    "        \n",
    "        # Extrai a tabela como uma lista de dicionários\n",
    "        table_data = page.extract_table()\n",
    "\n",
    "        # Converte a lista de dicionários para um DataFrame do pandas\n",
    "        df = pd.DataFrame(table_data)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fazendo tratamento na tabela 1 do pdf modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeçalho\n",
    "header = ['PRODUTOS', 'TIPO', 'UNIDADE EMBALAGEM', 'VARIAÇÃO ULTIMOS 12 MESES', 'MIN', 'MODAL', 'MAX', 'CLASSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Dia Semana:</td>\n",
       "      <td>segunda-feira</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>DATA:</td>\n",
       "      <td>24/04/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRODUTOS</td>\n",
       "      <td>TIPO</td>\n",
       "      <td>UNIDADE EMBALAGEM</td>\n",
       "      <td>VARIAÇÃO\\nULTIMOS\\n12 MESES</td>\n",
       "      <td>MIN</td>\n",
       "      <td>MODAL</td>\n",
       "      <td>MAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. FRUTAS NACIONAIS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACATE</td>\n",
       "      <td></td>\n",
       "      <td>Cx 18 kg</td>\n",
       "      <td>-64,29%</td>\n",
       "      <td>40,00</td>\n",
       "      <td>50,00</td>\n",
       "      <td>60,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACAXI ANANÁS</td>\n",
       "      <td>Grande</td>\n",
       "      <td>Unid 2,5 kg</td>\n",
       "      <td>S/C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1                  2  \\\n",
       "0                 None  Dia Semana:      segunda-feira   \n",
       "1             PRODUTOS         TIPO  UNIDADE EMBALAGEM   \n",
       "2  1. FRUTAS NACIONAIS                                   \n",
       "3              ABACATE                        Cx 18 kg   \n",
       "4       ABACAXI ANANÁS       Grande        Unid 2,5 kg   \n",
       "\n",
       "                             3      4      5           6  \n",
       "0                         None   None  DATA:  24/04/2023  \n",
       "1  VARIAÇÃO\\nULTIMOS\\n12 MESES    MIN  MODAL         MAX  \n",
       "2                                                         \n",
       "3                      -64,29%  40,00  50,00       60,00  \n",
       "4                          S/C                            "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cell generated by Data Wrangler.\n",
    "\"\"\"\n",
    "# tratamento v2 pag 1 tb 2\n",
    "def scan_tb_v2_p1_t1(df):\n",
    "    header = ['PRODUTOS', 'TIPO', 'UNIDADE EMBALAGEM', 'VARIAÇÃO ULTIMOS 12 MESES', 'MIN', 'MODAL', 'MAX']\n",
    "    df.columns = header\n",
    "\n",
    "    df = df.iloc[1: , :]\n",
    "   \n",
    "    # Change column type to string for column: 'PRODUTOS'\n",
    "    df = df.iloc[1: , :]\n",
    "    df['CLASSE'] = df['PRODUTOS'].iloc[0]\n",
    "    df = df.iloc[1: , :]\n",
    "    \n",
    "    # Replace all instances of \"\" with \"0\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MAX'] = df['MAX'].str.replace(\"^$\", \"0\", regex=True)\n",
    "\n",
    "    # Replace all instances of \"\" with \"S/C\" in column: 'UNIDADE EMBALAGEM'\n",
    "    df.loc[df['UNIDADE EMBALAGEM'].str.lower() == \"\".lower(), 'UNIDADE EMBALAGEM'] = \"S/C\"\n",
    "    \n",
    "    # Replace all instances of \",\" with \".\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MAX'] = df['MAX'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    \n",
    "    # Change column type to float16 for columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df = df.astype({'MIN': 'float16', 'MODAL': 'float16', 'MAX': 'float16'})\n",
    "    \n",
    "    # Change column type to string for columns: 'CLASSE', 'PRODUTOS' and 2 other columns\n",
    "    df = df.astype({'CLASSE': 'string', 'PRODUTOS': 'string', 'TIPO': 'string', 'UNIDADE EMBALAGEM': 'string'})\n",
    "    \n",
    "    # Convert text to uppercase in column: 'TIPO'\n",
    "    df['TIPO'] = df['TIPO'].str.upper()\n",
    "    return df\n",
    "\n",
    "df_temp = extrair_tabela_pdf(pdf_v2,0)\n",
    "df_temp.head()\n",
    "# df_scan_tb_v2_p1_t1 = scan_tb_v2_p1_t1(df_temp)\n",
    "# df_scan_tb_v2_p1_t1.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
