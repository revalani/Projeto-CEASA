{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Acessar site e coletar os PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instalar dependencias\n",
    "# %env\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_CEASA = 'https://www.ceasa.rj.gov.br'\n",
    "URL_CEASA_cotacao = URL_CEASA+'Cota%C3%A7%C3%A3o'\n",
    "\n",
    "PASTA_PDFs = \"./pdfs/\"\n",
    "PASTA_DADOS = \"./dados/\"\n",
    "\n",
    "ceasa_lista_pdf = PASTA_DADOS+\"ceasa_lista_pdf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### auxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barra de progresso\n",
    "# font:https://stackoverflow.com/questions/6169217/replace-console-output-in-python\n",
    "\n",
    "def print_r(str:str):\n",
    "    print(str, end='\\r')\n",
    "\n",
    "\n",
    "def print_percent_done(index, total, progress_state=None, bar_len=25, title='Processando'):\n",
    "    '''\n",
    "    index is expected to be 0 based index. \n",
    "    0 <= index < total\n",
    "    '''\n",
    "    percent_done = (index+1)/total*100\n",
    "    percent_done = round(percent_done, 1)\n",
    "\n",
    "    done = round(percent_done/(100/bar_len))\n",
    "    togo = bar_len-done\n",
    "\n",
    "    done_str = '█'*int(done)\n",
    "    togo_str = '░'*int(togo)\n",
    "\n",
    "    progress_state = f\"\\t Stage: {progress_state}\" if progress_state else ''\n",
    "\n",
    "    print(f'⏳{title}: [{done_str}{togo_str}] {percent_done}% done {progress_state}', end='\\r')\n",
    "\n",
    "    if round(percent_done) == 100:\n",
    "        print('\\t✅')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coleta linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.ceasa.rj.gov.brcota%c3%a7%c3%a3o', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0d1b29be80>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f0d1b29be80>: Failed to establish a new connection: [Errno -2] Name or service not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    789\u001b[0m )\n\u001b[1;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.ceasa.rj.gov.brcota%c3%a7%c3%a3o', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0d1b29be80>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/root/labs/Projeto ceasa/ETL_CEASA.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=88'>89</a>\u001b[0m \tdf_extração \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(ceasa_lista_pdf,sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mURL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnome_arquivo\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \tdf_extração\u001b[39m.\u001b[39mto_csv(ceasa_lista_pdf, sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m atualizar_base_pdf()\n",
      "\u001b[1;32m/root/labs/Projeto ceasa/ETL_CEASA.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39matualizar_base_pdf\u001b[39m():\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m \tpegar_links(URL_CEASA_cotacao)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m urls[:]:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \t\tprint_percent_done(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \t\t\u001b[39mlen\u001b[39m(df_extração) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(urls), \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m \t\t\u001b[39mlen\u001b[39m(df_extração), \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m \t\t\u001b[39mstr\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpdf extraidos \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(urls)\u001b[39m}\u001b[39;00m\u001b[39m de \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(df_extração)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m link atual \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m/root/labs/Projeto ceasa/ETL_CEASA.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpegar_links\u001b[39m(url):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \treqs \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \tsoup \u001b[39m=\u001b[39m BeautifulSoup(reqs\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/root/labs/Projeto%20ceasa/ETL_CEASA.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \t\u001b[39mfor\u001b[39;00m link \u001b[39min\u001b[39;00m soup\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39m#main a\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.ceasa.rj.gov.brcota%c3%a7%c3%a3o', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f0d1b29be80>: Failed to establish a new connection: [Errno -2] Name or service not known'))"
     ]
    }
   ],
   "source": [
    "# %%script echo skipping\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re #regex\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def foi_extraida(url):\n",
    "\treturn True if url in((df_extração['URL'].eq(url))) else False\n",
    "\n",
    "def pegar_links(url):\n",
    "\treqs = requests.get(url)\n",
    "\tsoup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "\n",
    "\tfor link in soup.select('#main a'):\n",
    "\t\t\n",
    "\t\ta = str(link.get('href'))\n",
    "\t\tprint_r(f'Qtds pdfs encontrados {len(urls)}, link atual: {a}')\n",
    "\t\tif \".pdf\" in a:\n",
    "\t\t\ta = 'https://www.ceasa.rj.gov.br'+ a\n",
    "\t\t\tif not foi_extraida(a):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\turls.append(a)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\t\tpegar_links(a)\n",
    "\n",
    "def extrair_dados_url(url):\n",
    "\t# pega nome do arquivo na URL\n",
    "\tnome_arquivo = url.split(\"/\")[-1]\n",
    "\tnome_arquivo = requests.utils.unquote(nome_arquivo) # type: ignore\n",
    "\n",
    "\t# padrao de dd mm yyyy para data\n",
    "\tmatches = re.findall(r'(\\d{2})\\s(\\d{2})\\s(\\d{4})', nome_arquivo)\n",
    "\tdata = dt.strptime(\"/\".join(matches[0]), \"%d/%m/%Y\")\n",
    "\n",
    "\treturn url,\"CEASA-RJ_\" + nome_arquivo.replace(\" \", \"_\") ,data.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "def pegar_pdf(url,nome_arquivo):\n",
    "\t# conferir se ja está na base local\n",
    "\tresponse = requests.get(url)\n",
    "\n",
    "\tif response.status_code == 200:\n",
    "\t\twith open(PASTA_PDFs+nome_arquivo, \"wb\") as f:\n",
    "\t\t\tf.write(response.content)\n",
    "\t\t\n",
    "\t\treturn True\n",
    "\n",
    "def add_csv(url, nome_arquivo,data):\n",
    "\tdata_to_file = {\n",
    "\t\t'URL': [url],\n",
    "\t\t'nome_arquivo': [nome_arquivo],\n",
    "\t\t'data': [data]\n",
    "\t} \n",
    "\tdf = pd.DataFrame(data_to_file)\n",
    "\tdf.to_csv(ceasa_lista_pdf, mode='a', index=False, header=False, sep=\";\")\n",
    "\n",
    "def atualizar_base_pdf():\n",
    "\tpegar_links(URL_CEASA_cotacao)\n",
    "\t\n",
    "\tfor x in urls[:]:\n",
    "\t\tprint_percent_done(\n",
    "\t\tlen(df_extração) - len(urls), \n",
    "\t\tlen(df_extração), \n",
    "\t\tstr(f'pdf extraidos {len(urls)} de {len(df_extração)} \\n\\t link atual {x}'))\n",
    "\n",
    "\t\t# if foi_extraida:\n",
    "\t\t# \tcontinue\n",
    "\t\t\n",
    "\t\turl, nome_arquivo, data = extrair_dados_url(x)\n",
    "\t\tpegar_pdf(url,nome_arquivo)\n",
    "\t\tadd_csv(url,nome_arquivo,data)\n",
    "\n",
    "\n",
    "# init\n",
    "\n",
    "try:\n",
    "    urls # type: ignore\n",
    "except:\n",
    "\turls = [] \n",
    "\n",
    "\n",
    "try:\n",
    "\tdf_extração = pd.read_csv(ceasa_lista_pdf,sep=\";\")\n",
    "except:\n",
    "\tdf_extração = pd.read_csv(ceasa_lista_pdf,sep=\";\", names = [\"URL\", \"nome_arquivo\",\"data\"])\n",
    "\tdf_extração.to_csv(ceasa_lista_pdf, sep=';', index=False)\n",
    "\n",
    "atualizar_base_pdf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratando os PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compressão paralelizada (muito custoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo skipping\n",
    "\n",
    "import PyPDF2\n",
    "import concurrent.futures\n",
    "\n",
    "def compress_pdf(input_path, output_path):\n",
    "    with open(input_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            page.compress_content_streams()\n",
    "            pdf_writer.add_page(page)\n",
    "\n",
    "        with open(output_path, 'wb') as output_file:\n",
    "            pdf_writer.write(output_file)\n",
    "\n",
    "def process_pdf(file_name):\n",
    "    print(f'arquivo atual: {file_name}')\n",
    "    compress_pdf(PASTA_PDFs + file_name, PASTA_PDFs + file_name)\n",
    "\n",
    "# Sua lista de arquivos\n",
    "files_to_process = df_extração[\"nome_arquivo\"].tolist()\n",
    "\n",
    "# Número máximo de threads (ajuste conforme necessário)\n",
    "max_threads = 4\n",
    "\n",
    "# Usando ThreadPoolExecutor para paralelizar\n",
    "with concurrent.futures.ThreadPoolExecutor(max_threads) as executor:\n",
    "    futures = [executor.submit(process_pdf, file_name) for file_name in files_to_process]\n",
    "\n",
    "    # Esperar que todas as threads concluam\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        count += 1 # type: ignore\n",
    "        print_percent_done(count, len(files_to_process), future.result()) # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo Tabelas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apartir de 01-03-2023 ouver mudança na formatação da tabela.\n",
    "trataremos as duas versões de PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Dia Semana:</td>\n",
       "      <td>quinta-feira</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>09/11/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRODUTOS</td>\n",
       "      <td>TIPO</td>\n",
       "      <td>UNIDADE EMBALAGEM</td>\n",
       "      <td>VARIAÇÃO\\nULTIMOS\\n12 MESES</td>\n",
       "      <td>MIN</td>\n",
       "      <td>MODAL</td>\n",
       "      <td>MAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. FRUTAS NACIONAIS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACATE</td>\n",
       "      <td></td>\n",
       "      <td>Cx 15 kg</td>\n",
       "      <td>-52,00%</td>\n",
       "      <td>50,00</td>\n",
       "      <td>60,00</td>\n",
       "      <td>65,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACAXI ANANÁS</td>\n",
       "      <td>Grande</td>\n",
       "      <td>Unid 2,5 kg</td>\n",
       "      <td>S/C</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1                  2  \\\n",
       "0                 None  Dia Semana:       quinta-feira   \n",
       "1             PRODUTOS         TIPO  UNIDADE EMBALAGEM   \n",
       "2  1. FRUTAS NACIONAIS                                   \n",
       "3              ABACATE                        Cx 15 kg   \n",
       "4       ABACAXI ANANÁS       Grande        Unid 2,5 kg   \n",
       "\n",
       "                             3      4      5           6  \n",
       "0                         None   None         09/11/2023  \n",
       "1  VARIAÇÃO\\nULTIMOS\\n12 MESES    MIN  MODAL         MAX  \n",
       "2                                                         \n",
       "3                      -52,00%  50,00  60,00       65,00  \n",
       "4                          S/C                            "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "\n",
    "pdf_modelo_v1 = PASTA_PDFs + \"CEASA-RJ_Boletim_diário_de_preços__03_01_2022_0.pdf\" \n",
    "pdf_modelo_v2 = PASTA_PDFs + \"CEASA-RJ_Boletim_diário_de_preços__24_04_2023.pdf\" \n",
    "\n",
    "def extrair_tabelas(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Itera sobre todas as páginas do PDF\n",
    "        for page_number in range(len(pdf.pages)):\n",
    "            page = pdf.pages[page_number]\n",
    "\n",
    "            # Extrai todas as tabelas na página\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            # Itera sobre todas as tabelas na página\n",
    "            for table_number, table in enumerate(tables):\n",
    "                print(f\"Tabela {table_number + 1} na página {page_number + 1}:\")\n",
    "                \n",
    "                # Itera sobre todas as linhas da tabela\n",
    "                for row_number, row in enumerate(table):\n",
    "                    print(f\"  Linha {row_number + 1}: {row}\")\n",
    "\n",
    "                print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separador entre tabelas\n",
    "\n",
    "\n",
    "def extrair_tabela_pdf(pdf_path, pagina=0):\n",
    "    # Abre o PDF com pdfplumber\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Seleciona a página desejada\n",
    "        page = pdf.pages[pagina]\n",
    "        \n",
    "        # Extrai a tabela como uma lista de dicionários\n",
    "        table_data = page.extract_table()\n",
    "\n",
    "        # Converte a lista de dicionários para um DataFrame do pandas\n",
    "        df = pd.DataFrame(table_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# t = extrair_tabela_pdf(PASTA_PDFs+'CEASA-RJ_Boletim_diário_de_preços__09_11_2023.pdf')\n",
    "# t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fazendo tratamento na tabela 1 do pdf modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeçalho\n",
    "header = ['PRODUTOS', 'TIPO', 'UNIDADE EMBALAGEM', 'VARIAÇÃO ULTIMOS 12 MESES', 'MIN', 'MODAL', 'MAX']\n",
    "\n",
    "#c Classes de alimentos\n",
    "classes = ['1. FRUTAS NACIONAIS',\n",
    "          '2. FRUTAS IMPORTADAS',\n",
    "          '3. HORTALIÇAS FRUTO',\n",
    "          '4. HORTALIÇAS FOLHA, FLOR E HASTE',\n",
    "          '5. HORTALIÇAS RAIZ, BULBO,TUBÉRCULO E RIZOMA',\n",
    "          '6. OVOS',\n",
    "          '7. PEIXE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento v2 pag 1 tb 1\n",
    "def scan_tb_v2_p1(df):\n",
    "    df.columns = header\n",
    "\n",
    "    # remove as 2 linhas inicias \n",
    "    df = df.iloc[2: , :]\n",
    "\n",
    "    # adiciona coluna classe\n",
    "    df['CLASSE'] = ''\n",
    "    \n",
    "    # Replace all instances of \"\" with \"0\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MAX'] = df['MAX'].str.replace(\"^$\", \"0\", regex=True)\n",
    "\n",
    "\n",
    "    # Replace all simbols of \"\" with \"S/C\" and \"%\" in columns: 'UNIDADE EMBALAGEM','VARIAÇÃO ULTIMOS 12 MESES'\n",
    "    df.loc[df['UNIDADE EMBALAGEM'].str.lower() == \"\".lower(), 'UNIDADE EMBALAGEM'] = \"S/C\"\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"%\", \"\", case=False, regex=False)\n",
    "    df['UNIDADE EMBALAGEM'] = df['UNIDADE EMBALAGEM'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "\n",
    "    \n",
    "    # Replace all instances of \",\" with \".\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MAX'] = df['MAX'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    \n",
    "    # Change column type to float32 for columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df = df.astype({'MIN': 'float32', 'MODAL': 'float32', 'MAX': 'float32'})\n",
    "    \n",
    "    # Change column type to string for columns: 'CLASSE', 'PRODUTOS' and 2 other columns\n",
    "    df = df.astype({'CLASSE': 'string', 'PRODUTOS': 'string', 'TIPO': 'string', 'UNIDADE EMBALAGEM': 'string'})\n",
    "    \n",
    "    # Convert text to uppercase in column: 'TIPO'\n",
    "    df['TIPO'] = df['TIPO'].str.upper()\n",
    "    return df\n",
    "\n",
    "# df_scan_tb_v2_p1 = scan_tb_v2_p1( extrair_tabela_pdf(pdf_v2,0) )\n",
    "# df_scan_tb_v2_p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento v2 pag 2 tb 1\n",
    "def scan_tb_v2_p2(df):\n",
    "    df.columns = header\n",
    "    \n",
    "    df = df.iloc[2: , :]\n",
    "    \n",
    "    # classe = df['PRODUTOS'].iloc[0] if str(df['PRODUTOS'].iloc[0]) in classes else \"\"\n",
    "    df['CLASSE'] = ''\n",
    "    \n",
    "    # Replace all instances of \"\" with \"0\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MAX'] = df['MAX'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    \n",
    "    # Replace all instances of \",\" with \".\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MAX'] = df['MAX'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    \n",
    "    # Change column type to float32 for columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df = df.astype({'MIN': 'float32', 'MODAL': 'float32', 'MAX': 'float32'})\n",
    "\n",
    "    # Change column type to string for columns: 'CLASSE', 'PRODUTOS' and 2 other columns\n",
    "    df = df.astype({'CLASSE': 'string', 'PRODUTOS': 'string', 'TIPO': 'string', 'UNIDADE EMBALAGEM': 'string'})\n",
    "    \n",
    "    # Convert text to uppercase in column: 'TIPO'\n",
    "    df['TIPO'] = df['TIPO'].str.upper()\n",
    "\n",
    "    # Replace all simbols of \"\" with \"S/C\" and \"%\" in columns: 'UNIDADE EMBALAGEM','VARIAÇÃO ULTIMOS 12 MESES'\n",
    "    df.loc[df['UNIDADE EMBALAGEM'].str.lower() == \"\".lower(), 'UNIDADE EMBALAGEM'] = \"S/C\"\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"%\", \"\", case=False, regex=False)\n",
    "    df['UNIDADE EMBALAGEM'] = df['UNIDADE EMBALAGEM'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tratamento v2 pag 3 tb 1 \n",
    "def scan_tb_v2_p3(df):\n",
    "    # define cabeçalhos\n",
    "    df.columns = header\n",
    "    \n",
    "    # Remove primeiras linhas\n",
    "    df = df.iloc[2: , :]\n",
    "    \n",
    "    # Adiciona colula classe\n",
    "    df['CLASSE'] = ''\n",
    "    \n",
    "    # Replace all instances of \"\" with \"0\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    df['MAX'] = df['MAX'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    \n",
    "    # Replace all simbols of \"\" with \"S/C\" and \"%\" in columns: 'UNIDADE EMBALAGEM','VARIAÇÃO ULTIMOS 12 MESES'\n",
    "    df.loc[df['UNIDADE EMBALAGEM'].str.lower() == \"\".lower(), 'UNIDADE EMBALAGEM'] = \"S/C\"\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"%\", \"\", case=False, regex=False)\n",
    "    df['UNIDADE EMBALAGEM'] = df['UNIDADE EMBALAGEM'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    \n",
    "    # Replace all instances of \",\" with \".\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df['MIN'] = df['MIN'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MODAL'] = df['MODAL'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    df['MAX'] = df['MAX'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    \n",
    "    # Change column type to float32 for columns: 'MIN', 'MODAL', 'MAX'\n",
    "    df = df.astype({'MIN': 'float32', 'MODAL': 'float32', 'MAX': 'float32'})\n",
    "    \n",
    "    # Change column type to string for columns: 'CLASSE', 'PRODUTOS' and 2 other columns\n",
    "    df = df.astype({'CLASSE': 'string', 'PRODUTOS': 'string', 'TIPO': 'string', 'UNIDADE EMBALAGEM': 'string'})\n",
    "    \n",
    "    # Convert text to uppercase in column: 'TIPO'\n",
    "    df['TIPO'] = df['TIPO'].str.upper()\n",
    "    return df\n",
    "\n",
    "# df_scan_tb_v2_p3 = scan_tb_v2_p3( extrair_tabela_pdf(pdf_v2,2))\n",
    "# df_scan_tb_v2_p3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tramento PDF v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### tratamento pdf v1 p1 t1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extrair_tabela_pdf(pdf_v1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabeçalho\n",
    "header = ['PRODUTOS', 'TIPO', 'UNIDADE EMBALAGEM', 'VARIAÇÃO ULTIMOS 12 MESES', 'MIN', 'MODAL', 'MAX']\n",
    "\n",
    "#c Classes de alimentos\n",
    "classes = ['1. FRUTAS NACIONAIS',\n",
    "          '2. FRUTAS IMPORTADAS',\n",
    "          '3. HORTALIÇAS FRUTO',\n",
    "          '4. HORTALIÇAS FOLHA, FLOR E HASTE',\n",
    "          '5. HORTALIÇAS RAIZ, BULBO,TUBÉRCULO E RIZOMA',\n",
    "          '6. OVOS',\n",
    "          '7. PEIXE']\n",
    "\n",
    "# tratamendo geral pdf v2\n",
    "def tratamento_1_tbv1(df):\n",
    "    # define cabeçalhos\n",
    "    df.columns = header\n",
    "    \n",
    "    # Remove primeiras linhas\n",
    "    df = df.iloc[2: , :]\n",
    "    \n",
    "    # Adiciona colula classe\n",
    "    df.loc[:, 'CLASSE'] = ''\n",
    "\n",
    "    return df\n",
    "\n",
    "# Compreensão de lista para criar a lista de dataframes\n",
    "# list_df_tratamento_1_tbv2 = [ tratamento_1_tbv1( extrair_tabela_pdf(pdf_v1, i)) for i in range(14) ]\n",
    "\n",
    "# Concatenar os dataframes da lista\n",
    "# df = pd.concat(list_df_tratamento_1_tbv2.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tramento PDF v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# tratamendo geral pdf v2\n",
    "def tratamento_1_tbv2(df):\n",
    "    remore\n",
    "    # define cabeçalhos\n",
    "    df.columns = header\n",
    "    \n",
    "    # Remove primeiras linhas\n",
    "    df = df.iloc[2: , :]\n",
    "    \n",
    "    # Adiciona colula classe\n",
    "    df.loc[:, 'CLASSE'] = ''\n",
    "\n",
    "    return df\n",
    "\n",
    "def tratamento_2_tbv2(df, arquivo='', data_pdf = ''):\n",
    "    # preencher class\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Colulas de arquivo e data\n",
    "    df['DATA'] = data_pdf\n",
    "    df['ARQUIVO'] = arquivo\n",
    "    \n",
    "    # preenche classe\n",
    "    def preenche_classe(df):\n",
    "        df = df.reset_index(drop=True)    \n",
    "        \n",
    "        current_class = ''  # Para rastrear a classe atual\n",
    "        for index, row in df.iterrows():\n",
    "            if row['PRODUTOS'] in classes:\n",
    "                current_class = row['PRODUTOS']\n",
    "            df.at[index,'CLASSE'] = current_class\n",
    "    \n",
    "        df = df[df['PRODUTOS'] != df['CLASSE']]\n",
    "        df = df.reset_index(drop=True)    \n",
    "    \n",
    "        return df\n",
    "    \n",
    "    df = preenche_classe(df)\n",
    "    # # Replace all instances of \"\" with \"0\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    # df['MIN'] = df['MIN'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    # df['MODAL'] = df['MODAL'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    # df['MAX'] = df['MAX'].str.replace(\"^$\", \"0\", regex=True)\n",
    "    \n",
    "    # # Replace all instances of \",\" with \".\" in columns: 'MIN', 'MODAL', 'MAX'\n",
    "    # df['MIN'] = df['MIN'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    # df['MODAL'] = df['MODAL'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    # df['MAX'] = df['MAX'].str.replace(\",\", \".\", case=False, regex=False)\n",
    "    \n",
    "    # # Change column type to float32 for columns: 'MIN', 'MODAL', 'MAX'\n",
    "    # df = df.astype({'MIN': 'float32', 'MODAL': 'float32', 'MAX': 'float32'})\n",
    "    \n",
    "    # # Change column type to string for columns: 'CLASSE', 'PRODUTOS' and 2 other columns\n",
    "    # df = df.astype({'CLASSE': 'string', 'PRODUTOS': 'string', 'TIPO': 'string', 'UNIDADE EMBALAGEM': 'string'})\n",
    "    \n",
    "    # # Convert text to uppercase in column: 'TIPO'\n",
    "    # df['TIPO'] = df['TIPO'].str.upper()\n",
    "    \n",
    "    # # Replace all simbols of \"\" with \"S/C\" and \"%\" in columns: 'UNIDADE EMBALAGEM','VARIAÇÃO ULTIMOS 12 MESES'\n",
    "    # df.loc[df['UNIDADE EMBALAGEM'].str.lower() == \"\".lower(), 'UNIDADE EMBALAGEM'] = \"S/C\"\n",
    "    # df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    # df['VARIAÇÃO ULTIMOS 12 MESES'] = df['VARIAÇÃO ULTIMOS 12 MESES'].str.replace(\"%\", \"\", case=False, regex=False)\n",
    "    # df['UNIDADE EMBALAGEM'] = df['UNIDADE EMBALAGEM'].str.replace(\"s/c\", \"\", case=False, regex=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def pdf_v2_para_tabela(pdf_v2,data=None,):        \n",
    "    # Compreensão de lista para criar a lista de dataframes\n",
    "    list_df_tratamento_1_tbv2 = [ tratamento_1_tbv2( extrair_tabela_pdf(PASTA_PDFs + pdf_v2, i)) for i in range(5) ]\n",
    "\n",
    "    # Concatenar os dataframes da lista\n",
    "    df = pd.concat(list_df_tratamento_1_tbv2.copy())\n",
    "    return tratamento_2_tbv2(df,pdf_v2,data)\n",
    "\n",
    "\n",
    "# df = pdf_v2_para_tabela(PASTA_PDFs +'CEASA-RJ_Boletim_diário_de_preços__09_11_2023.pdf')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 438 09-11-2023\n",
      "1 438 08-11-2023\n",
      "2 438 07-11-2023\n",
      "3 438 06-11-2023\n",
      "4 438 01-11-2023\n",
      "5 438 31-10-2023\n",
      "6 438 30-10-2023\n",
      "7 438 27-10-2023\n",
      "8 438 26-10-2023\n",
      "9 438 25-10-2023\n",
      "10 438 24-10-2023\n",
      "11 438 23-10-2023\n",
      "12 438 20-10-2023\n",
      "13 438 19-10-2023\n",
      "14 438 18-10-2023\n",
      "15 438 17-10-2023\n",
      "16 438 11-10-2023\n",
      "17 438 10-10-2023\n",
      "18 438 09-10-2023\n",
      "19 438 06-10-2023\n",
      "20 438 05-10-2023\n",
      "21 438 04-10-2023\n",
      "22 438 03-10-2023\n",
      "23 438 02-10-2023\n",
      "24 438 29-09-2023\n",
      "25 438 28-09-2023\n",
      "26 438 27-09-2023\n",
      "27 438 26-09-2023\n",
      "28 438 25-09-2023\n",
      "29 438 22-09-2023\n",
      "30 438 21-09-2023\n",
      "31 438 20-09-2023\n",
      "32 438 19-09-2023\n",
      "33 438 18-09-2023\n",
      "34 438 15-09-2023\n",
      "35 438 14-09-2023\n",
      "36 438 13-09-2023\n",
      "37 438 12-09-2023\n",
      "38 438 11-09-2023\n",
      "39 438 06-09-2023\n",
      "40 438 05-09-2023\n",
      "41 438 04-09-2023\n",
      "42 438 01-09-2023\n",
      "86 438 31-08-2023\n",
      "87 438 30-08-2023\n",
      "88 438 29-08-2023\n",
      "89 438 28-08-2023\n",
      "90 438 25-08-2023\n",
      "91 438 24-08-2023\n",
      "92 438 23-08-2023\n",
      "93 438 22-08-2023\n",
      "94 438 21-08-2023\n",
      "95 438 18-08-2023\n",
      "96 438 17-08-2023\n",
      "97 438 16-08-2023\n",
      "98 438 15-08-2023\n",
      "99 438 14-08-2023\n",
      "100 438 11-08-2023\n",
      "101 438 10-08-2023\n",
      "102 438 09-08-2023\n",
      "103 438 08-08-2023\n",
      "104 438 07-08-2023\n",
      "105 438 04-08-2023\n",
      "106 438 03-08-2023\n",
      "107 438 02-08-2023\n",
      "108 438 01-08-2023\n",
      "109 438 31-07-2023\n",
      "110 438 28-07-2023\n",
      "111 438 27-07-2023\n",
      "112 438 26-07-2023\n",
      "113 438 25-07-2023\n",
      "114 438 24-07-2023\n",
      "115 438 21-07-2023\n",
      "116 438 20-07-2023\n",
      "117 438 19-07-2023\n",
      "118 438 18-07-2023\n",
      "119 438 17-07-2023\n",
      "120 438 14-07-2023\n",
      "121 438 13-07-2023\n",
      "122 438 12-07-2023\n",
      "123 438 11-07-2023\n",
      "124 438 10-07-2023\n",
      "125 438 07-07-2023\n",
      "126 438 06-07-2023\n",
      "127 438 05-07-2023\n",
      "128 438 04-07-2023\n",
      "129 438 03-07-2023\n",
      "130 438 30-06-2023\n",
      "131 438 29-06-2023\n",
      "132 438 28-06-2023\n",
      "133 438 27-06-2023\n",
      "134 438 26-06-2023\n",
      "135 438 23-06-2023\n",
      "136 438 22-06-2023\n",
      "137 438 21-06-2023\n",
      "138 438 20-06-2023\n",
      "139 438 19-06-2023\n",
      "140 438 16-06-2023\n",
      "141 438 15-06-2023\n",
      "142 438 14-06-2023\n",
      "143 438 13-06-2023\n",
      "144 438 12-06-2023\n",
      "145 438 07-06-2023\n",
      "146 438 06-06-2023\n",
      "147 438 05-06-2023\n",
      "148 438 02-06-2023\n",
      "149 438 01-06-2023\n",
      "150 438 31-05-2023\n",
      "151 438 30-05-2023\n",
      "152 438 29-05-2023\n",
      "153 438 26-05-2023\n",
      "154 438 25-05-2023\n",
      "155 438 24-05-2023\n",
      "156 438 23-05-2023\n",
      "157 438 22-05-2023\n",
      "158 438 19-05-2023\n",
      "159 438 18-05-2023\n",
      "160 438 17-05-2023\n",
      "161 438 16-05-2023\n",
      "162 438 15-05-2023\n",
      "163 438 12-05-2023\n",
      "164 438 11-05-2023\n",
      "165 438 10-05-2023\n",
      "166 438 09-05-2023\n",
      "167 438 08-05-2023\n",
      "168 438 05-05-2023\n",
      "169 438 04-05-2023\n",
      "170 438 03-05-2023\n",
      "171 438 02-05-2023\n",
      "172 438 28-04-2023\n",
      "173 438 27-04-2023\n",
      "174 438 26-04-2023\n",
      "175 438 25-04-2023\n",
      "176 438 24-04-2023\n",
      "177 438 20-04-2023\n",
      "178 438 19-04-2023\n",
      "179 438 18-04-2023\n",
      "180 438 17-04-2023\n",
      "181 438 14-04-2023\n",
      "182 438 13-04-2023\n",
      "183 438 12-04-2023\n",
      "184 438 11-04-2023\n",
      "185 438 10-04-2023\n",
      "186 438 05-04-2023\n",
      "187 438 04-04-2023\n",
      "188 438 03-04-2023\n",
      "189 438 31-03-2023\n",
      "190 438 30-03-2023\n",
      "191 438 29-03-2023\n",
      "192 438 28-03-2023\n",
      "193 438 27-03-2023\n",
      "194 438 24-03-2023\n",
      "195 438 23-03-2023\n",
      "196 438 22-03-2023\n",
      "197 438 21-03-2023\n",
      "198 438 20-03-2023\n",
      "199 438 17-03-2023\n",
      "200 438 16-03-2023\n",
      "201 438 15-03-2023\n",
      "202 438 14-03-2023\n",
      "203 438 13-03-2023\n",
      "204 438 10-03-2023\n",
      "205 438 09-03-2023\n",
      "206 438 08-03-2023\n",
      "207 438 07-03-2023\n",
      "208 438 06-03-2023\n",
      "209 438 03-03-2023\n",
      "210 438 02-03-2023\n",
      "211 438 01-03-2023\n",
      "212 438 28-02-2023\n",
      "213 438 27-02-2023\n",
      "214 438 24-02-2023\n",
      "215 438 23-02-2023\n",
      "216 438 16-02-2023\n",
      "217 438 15-02-2023\n",
      "218 438 14-02-2023\n",
      "219 438 13-02-2023\n",
      "220 438 10-02-2023\n",
      "221 438 09-02-2023\n",
      "222 438 08-02-2023\n",
      "223 438 07-02-2023\n",
      "224 438 06-02-2023\n",
      "225 438 03-02-2023\n",
      "226 438 02-02-2023\n",
      "227 438 01-02-2023\n",
      "228 438 31-01-2023\n",
      "229 438 30-01-2023\n",
      "230 438 27-01-2023\n",
      "231 438 26-01-2023\n",
      "232 438 25-01-2023\n",
      "233 438 24-01-2023\n",
      "234 438 23-01-2023\n",
      "235 438 19-01-2023\n",
      "236 438 18-01-2023\n",
      "237 438 17-01-2023\n",
      "238 438 16-01-2023\n",
      "239 438 13-01-2023\n",
      "240 438 12-01-2023\n",
      "241 438 11-01-2023\n",
      "242 438 10-01-2023\n",
      "243 438 09-01-2023\n",
      "244 438 06-01-2023\n",
      "245 438 05-01-2023\n",
      "246 438 04-01-2023\n",
      "247 438 03-01-2023\n",
      "248 438 02-01-2023\n",
      "249 438 30-12-2022\n",
      "250 438 29-12-2022\n",
      "251 438 28-12-2022\n",
      "252 438 27-12-2022\n",
      "253 438 26-12-2022\n",
      "254 438 23-12-2022\n",
      "255 438 22-12-2022\n",
      "256 438 21-12-2022\n",
      "257 438 20-12-2022\n",
      "258 438 19-12-2022\n",
      "259 438 16-12-2022\n",
      "260 438 15-12-2022\n",
      "261 438 14-12-2022\n",
      "262 438 13-12-2022\n",
      "263 438 12-12-2022\n",
      "264 438 09-12-2022\n",
      "265 438 08-12-2022\n",
      "266 438 07-12-2022\n",
      "267 438 06-12-2022\n",
      "268 438 05-12-2022\n",
      "269 438 02-12-2022\n",
      "270 438 01-12-2022\n",
      "271 438 30-11-2022\n",
      "272 438 29-11-2022\n",
      "273 438 25-11-2022\n",
      "274 438 24-11-2022\n",
      "275 438 23-11-2022\n",
      "276 438 22-11-2022\n",
      "277 438 21-11-2022\n",
      "278 438 18-11-2022\n",
      "279 438 17-11-2022\n",
      "280 438 16-11-2022\n",
      "281 438 11-11-2022\n",
      "282 438 10-11-2022\n",
      "283 438 09-11-2022\n",
      "284 438 08-11-2022\n",
      "285 438 07-11-2022\n",
      "286 438 04-11-2022\n",
      "287 438 03-11-2022\n",
      "288 438 01-11-2022\n",
      "289 438 31-10-2022\n",
      "290 438 28-10-2022\n",
      "291 438 27-10-2022\n",
      "292 438 26-10-2022\n",
      "293 438 25-10-2022\n",
      "294 438 24-10-2022\n",
      "295 438 21-10-2022\n",
      "296 438 20-10-2022\n",
      "297 438 19-10-2022\n",
      "298 438 18-10-2022\n",
      "299 438 14-10-2022\n",
      "300 438 13-10-2022\n",
      "301 438 11-10-2022\n",
      "302 438 10-10-2022\n",
      "303 438 07-10-2022\n",
      "304 438 06-10-2022\n",
      "305 438 04-10-2022\n",
      "306 438 03-10-2022\n",
      "307 438 29-09-2022\n",
      "308 438 28-09-2022\n",
      "309 438 27-09-2022\n",
      "310 438 26-09-2022\n",
      "311 438 23-09-2022\n",
      "312 438 22-09-2022\n",
      "313 438 21-09-2022\n",
      "314 438 20-09-2022\n",
      "315 438 19-09-2022\n",
      "316 438 16-09-2022\n",
      "317 438 15-09-2022\n",
      "318 438 14-09-2022\n",
      "319 438 13-09-2022\n",
      "320 438 12-09-2022\n",
      "321 438 09-09-2022\n",
      "322 438 08-09-2022\n",
      "323 438 06-09-2022\n",
      "324 438 05-09-2022\n",
      "325 438 02-09-2022\n",
      "326 438 01-09-2022\n",
      "327 438 26-08-2022\n",
      "328 438 25-08-2022\n",
      "329 438 24-08-2022\n",
      "330 438 23-08-2022\n",
      "331 438 22-08-2022\n",
      "332 438 19-08-2022\n",
      "333 438 18-08-2022\n",
      "334 438 17-08-2022\n",
      "335 438 16-08-2022\n",
      "336 438 15-08-2022\n",
      "337 438 12-08-2022\n",
      "338 438 11-08-2022\n",
      "339 438 10-08-2022\n",
      "340 438 09-08-2022\n",
      "341 438 08-08-2022\n",
      "342 438 05-08-2022\n",
      "343 438 04-08-2022\n",
      "344 438 03-08-2022\n",
      "345 438 02-08-2022\n",
      "346 438 01-08-2022\n",
      "347 438 28-07-2022\n",
      "348 438 27-07-2022\n",
      "349 438 26-07-2022\n",
      "350 438 25-07-2022\n",
      "351 438 22-07-2022\n",
      "352 438 21-07-2022\n",
      "353 438 20-07-2022\n",
      "354 438 19-07-2022\n",
      "355 438 18-07-2022\n",
      "356 438 15-07-2022\n",
      "357 438 14-07-2022\n",
      "358 438 13-07-2022\n",
      "359 438 12-07-2022\n",
      "360 438 11-07-2022\n",
      "361 438 08-07-2022\n",
      "362 438 07-07-2022\n",
      "363 438 06-07-2022\n",
      "364 438 05-07-2022\n",
      "365 438 04-07-2022\n",
      "366 438 01-07-2022\n",
      "367 438 30-06-2022\n",
      "368 438 29-06-2022\n",
      "369 438 28-06-2022\n",
      "370 438 27-06-2022\n",
      "371 438 24-06-2022\n",
      "372 438 23-06-2022\n",
      "373 438 22-06-2022\n",
      "374 438 21-06-2022\n",
      "375 438 20-06-2022\n",
      "376 438 15-06-2022\n",
      "377 438 14-06-2022\n",
      "378 438 13-06-2022\n",
      "379 438 10-06-2022\n",
      "380 438 09-06-2022\n",
      "381 438 08-06-2022\n",
      "382 438 07-06-2022\n",
      "383 438 06-06-2022\n",
      "384 438 03-06-2022\n",
      "385 438 02-06-2022\n",
      "386 438 01-06-2022\n",
      "387 438 27-05-2022\n",
      "388 438 26-05-2022\n",
      "389 438 25-05-2022\n",
      "390 438 24-05-2022\n",
      "391 438 23-05-2022\n",
      "392 438 20-05-2022\n",
      "393 438 19-05-2022\n",
      "394 438 18-05-2022\n",
      "395 438 17-05-2022\n",
      "396 438 16-05-2022\n",
      "397 438 13-05-2022\n",
      "398 438 12-05-2022\n",
      "399 438 11-05-2022\n",
      "400 438 10-05-2022\n",
      "401 438 09-05-2022\n",
      "402 438 06-05-2022\n",
      "403 438 05-05-2022\n",
      "404 438 04-05-2022\n",
      "405 438 03-05-2022\n",
      "406 438 02-05-2022\n",
      "407 438 29-04-2022\n",
      "408 438 28-04-2022\n",
      "409 438 27-04-2022\n",
      "410 438 26-04-2022\n",
      "411 438 25-04-2022\n",
      "412 438 19-04-2022\n",
      "413 438 18-04-2022\n",
      "414 438 13-04-2022\n",
      "415 438 12-04-2022\n",
      "416 438 11-04-2022\n",
      "417 438 08-04-2022\n",
      "418 438 07-04-2022\n",
      "419 438 06-04-2022\n",
      "420 438 05-04-2022\n",
      "421 438 04-04-2022\n",
      "422 438 01-04-2022\n",
      "423 438 30-03-2022\n",
      "424 438 29-03-2022\n",
      "425 438 28-03-2022\n",
      "426 438 25-03-2022\n",
      "427 438 24-03-2022\n",
      "428 438 23-03-2022\n",
      "429 438 22-03-2022\n",
      "430 438 21-03-2022\n",
      "431 438 18-03-2022\n",
      "432 438 17-03-2022\n",
      "433 438 16-03-2022\n",
      "434 438 15-03-2022\n",
      "435 438 14-03-2022\n",
      "436 438 11-03-2022\n",
      "437 438 10-03-2022\n",
      "438 438 09-03-2022\n",
      "439 438 08-03-2022\n",
      "440 438 07-03-2022\n",
      "441 438 04-03-2022\n",
      "442 438 03-03-2022\n",
      "443 438 25-02-2022\n",
      "444 438 24-02-2022\n",
      "445 438 23-02-2022\n",
      "446 438 22-02-2022\n",
      "447 438 21-02-2022\n",
      "448 438 18-02-2022\n",
      "449 438 17-02-2022\n",
      "450 438 16-02-2022\n",
      "451 438 15-02-2022\n",
      "452 438 14-02-2022\n",
      "453 438 11-02-2022\n",
      "454 438 10-02-2022\n",
      "455 438 09-02-2022\n",
      "456 438 08-02-2022\n",
      "457 438 07-02-2022\n",
      "458 438 04-02-2022\n",
      "459 438 03-02-2022\n",
      "460 438 02-02-2022\n",
      "461 438 01-02-2022\n",
      "462 438 31-01-2022\n",
      "463 438 28-01-2022\n",
      "464 438 27-01-2022\n",
      "465 438 26-01-2022\n",
      "466 438 25-01-2022\n",
      "467 438 24-01-2022\n",
      "468 438 19-01-2022\n",
      "469 438 18-01-2022\n",
      "470 438 17-01-2022\n",
      "471 438 14-01-2022\n",
      "472 438 13-01-2022\n",
      "473 438 12-01-2022\n",
      "474 438 11-01-2022\n",
      "475 438 10-01-2022\n",
      "476 438 07-01-2022\n",
      "477 438 06-01-2022\n",
      "478 438 05-01-2022\n",
      "479 438 04-01-2022\n",
      "480 438 03-01-2022\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "# Suprime os avisos SettingWithCopyWarning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "def extrair_tb_pdf_V2():\n",
    "    df_pdfs_v2 = pd.read_csv(ceasa_lista_pdf, sep=',')\n",
    "\n",
    "    df_pdfs_v2 = df_pdfs_v2.drop_duplicates(subset=['NOME_ARQUIVO'])\n",
    "    df_pdfs_v2 = df_pdfs_v2[:]\n",
    "    \n",
    "    len = df_pdfs_v2.shape[0]\n",
    "    lista_pdf_v2 = []\n",
    "    \n",
    "    for index, row in df_pdfs_v2.iterrows():\n",
    "        arquivo = row['NOME_ARQUIVO']\n",
    "        data = row['DATA']\n",
    "        print(index, len, data)\n",
    "\n",
    "        data = dt.strptime(data, \"%d-%m-%Y\")\n",
    "        data_pdf_v2 = dt.strptime('01-03-2023', \"%d-%m-%Y\")\n",
    "\n",
    "        if data > data_pdf_v2:\n",
    "            df = pdf_v2_para_tabela(\n",
    "                arquivo, data.strftime(\"%d-%m-%Y\"))\n",
    "\n",
    "            lista_pdf_v2.append(df)\n",
    "\n",
    "    df = pd.concat(lista_pdf_v2)\n",
    "    return df\n",
    "\n",
    "\n",
    "df = extrair_tb_pdf_V2()\n",
    "\n",
    "df.to_csv(PASTA_DADOS + 'dados_pdfs_v2.csv',index=False)\n",
    "df.to_parquet(PASTA_DADOS + 'dados_pdfs_v2.parquet',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
